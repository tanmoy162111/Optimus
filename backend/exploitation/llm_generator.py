"""
LLM Exploit Generator

Uses Ollama LLM to generate:
- Custom exploit code for discovered vulnerabilities
- Payload adaptations for WAF bypass
- Multi-step attack chains
- Exploit modifications for specific targets

This is Phase 2 of the architecture upgrade, building on Phase 1's
Exploit Template Database and Payload Crafter.

Integration Points:
- exploitation/exploit_db.py: Enhances templates with LLM generation
- exploitation/payload_crafter.py: Generates custom payloads via LLM
- inference/ollama_client.py: Uses existing Ollama infrastructure
- autonomous_agent.py: Called during exploitation phase
"""

import json
import logging
import re
import time
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import Dict, List, Any, Optional, Tuple

logger = logging.getLogger(__name__)


class GenerationType(Enum):
    """Types of exploit generation"""
    EXPLOIT_CODE = "exploit_code"
    PAYLOAD_ADAPT = "payload_adapt"
    WAF_BYPASS = "waf_bypass"
    ATTACK_CHAIN = "attack_chain"
    PRIVESC_SCRIPT = "privesc_script"
    PERSISTENCE = "persistence"
    CUSTOM_TOOL = "custom_tool"


@dataclass
class GenerationRequest:
    """Request for LLM exploit generation"""
    generation_type: GenerationType
    vulnerability: Dict[str, Any]
    target_context: Dict[str, Any]
    constraints: List[str] = field(default_factory=list)
    existing_payloads: List[str] = field(default_factory=list)
    failed_attempts: List[Dict] = field(default_factory=list)
    max_tokens: int = 2048
    temperature: float = 0.3


@dataclass
class GeneratedExploit:
    """Result of LLM exploit generation"""
    code: str
    language: str
    description: str
    generation_type: GenerationType
    execution_steps: List[str] = field(default_factory=list)
    dependencies: List[str] = field(default_factory=list)
    success_indicators: List[str] = field(default_factory=list)
    cleanup_commands: List[str] = field(default_factory=list)
    confidence: float = 0.5
    warnings: List[str] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)
    timestamp: str = ""
    
    def __post_init__(self):
        if not self.timestamp:
            self.timestamp = datetime.now().isoformat()
    
    def to_dict(self) -> Dict:
        return {
            "code": self.code,
            "language": self.language,
            "description": self.description,
            "generation_type": self.generation_type.value,
            "execution_steps": self.execution_steps,
            "dependencies": self.dependencies,
            "success_indicators": self.success_indicators,
            "cleanup_commands": self.cleanup_commands,
            "confidence": self.confidence,
            "warnings": self.warnings,
            "metadata": self.metadata,
            "timestamp": self.timestamp,
        }


class LLMExploitGenerator:
    """
    Generates exploit code using Ollama LLM.
    
    Capabilities:
    - Generate custom exploits for CVEs
    - Adapt payloads for WAF bypass
    - Create multi-step attack chains
    - Generate privilege escalation scripts
    - Create persistence mechanisms
    
    Usage:
        generator = LLMExploitGenerator()
        
        # Generate exploit for SQLi
        result = generator.generate_exploit(
            vulnerability={'type': 'sql_injection', 'dbms': 'mysql'},
            target={'url': 'http://target/page', 'waf': True}
        )
        
        # Adapt payload for WAF
        adapted = generator.adapt_payload_for_waf(
            original_payload="' OR 1=1--",
            waf_type="cloudflare",
            failed_attempts=["' OR 1=1--", "' OR '1'='1"]
        )
    """
    
    def __init__(self, ollama_client=None):
        """
        Initialize LLM Exploit Generator.
        
        Args:
            ollama_client: Existing OllamaClient instance (will create if None)
        """
        self.ollama_client = ollama_client
        self._init_client()
        
        # Generation history for learning
        self.generation_history: List[GeneratedExploit] = []
        
        # Prompt templates
        self._init_prompts()
        
        logger.info("[LLMExploitGenerator] Initialized")
    
    def _init_client(self):
        """Initialize or verify Ollama client"""
        if self.ollama_client is None:
            try:
                from inference.ollama_client import OllamaClient, OllamaConfig
                
                # Use a code-focused model for exploit generation
                config = OllamaConfig(
                    model="codellama:7b-instruct",  # Good for code generation
                    temperature=0.3,  # Some creativity but mostly focused
                    max_tokens=4096,
                    timeout=180  # Longer timeout for complex generation
                )
                self.ollama_client = OllamaClient(config)
            except ImportError:
                logger.warning("[LLMExploitGenerator] OllamaClient not available")
                self.ollama_client = None
    
    def _init_prompts(self):
        """Initialize prompt templates for different generation types"""
        
        self.system_prompts = {
            GenerationType.EXPLOIT_CODE: """You are an expert penetration testing assistant helping security professionals.
Your role is to generate exploit code for AUTHORIZED security testing only.
Always include proper error handling and cleanup.
Generate code that is safe, targeted, and follows ethical guidelines.
Output ONLY the code with brief inline comments. No explanations outside the code.""",

            GenerationType.PAYLOAD_ADAPT: """You are a security payload specialist.
Your role is to adapt and modify payloads for authorized penetration testing.
Focus on technique variation while maintaining the same effect.
Consider encoding, obfuscation, and evasion techniques.
Output the adapted payload directly, followed by a brief explanation.""",

            GenerationType.WAF_BYPASS: """You are a WAF bypass specialist for authorized security testing.
Your role is to find alternative payload encodings that bypass web application firewalls.
Use techniques like:
- Case variation
- Encoding (URL, Unicode, HTML entities)
- Comment insertion
- Alternative syntax
- Chunked encoding
Output multiple bypass variants, each on a new line.""",

            GenerationType.ATTACK_CHAIN: """You are an attack chain architect for penetration testing.
Your role is to design multi-step attack sequences that chain vulnerabilities.
Consider dependencies between steps and fallback options.
Output a structured attack plan with clear steps.""",

            GenerationType.PRIVESC_SCRIPT: """You are a privilege escalation specialist.
Generate scripts that enumerate and exploit privilege escalation vectors.
Focus on common misconfigurations and known vulnerabilities.
Include checks before exploitation to avoid system damage.""",

            GenerationType.PERSISTENCE: """You are a persistence mechanism specialist for red team operations.
Generate techniques to maintain access during authorized testing.
Focus on stealthy, reversible methods that can be easily cleaned up.
Always include cleanup/removal instructions.""",
        }
    
    def is_available(self) -> bool:
        """Check if LLM is available for generation"""
        if self.ollama_client is None:
            return False
        return self.ollama_client.is_available()
    
    def generate_exploit(
        self,
        vulnerability: Dict[str, Any],
        target: Dict[str, Any],
        constraints: List[str] = None,
        language: str = "python"
    ) -> Optional[GeneratedExploit]:
        """
        Generate exploit code for a vulnerability.
        
        Args:
            vulnerability: Vulnerability details (type, cve, details)
            target: Target context (url, os, waf, technologies)
            constraints: Generation constraints (no reverse shell, etc.)
            language: Preferred programming language
            
        Returns:
            GeneratedExploit or None if generation failed
        """
        if not self.is_available():
            logger.warning("[LLMExploitGenerator] LLM not available")
            return None
        
        constraints = constraints or []
        
        prompt = self._build_exploit_prompt(vulnerability, target, constraints, language)
        system_prompt = self.system_prompts[GenerationType.EXPLOIT_CODE]
        
        response = self.ollama_client.generate(prompt, system_prompt)
        
        if response:
            return self._parse_exploit_response(
                response, 
                GenerationType.EXPLOIT_CODE,
                language,
                vulnerability
            )
        
        return None
    
    def adapt_payload_for_waf(
        self,
        original_payload: str,
        waf_type: str = "generic",
        payload_type: str = "sqli",
        failed_attempts: List[str] = None
    ) -> Optional[GeneratedExploit]:
        """
        Adapt a payload to bypass WAF.
        
        Args:
            original_payload: Original payload that was blocked
            waf_type: Type of WAF (cloudflare, akamai, modsecurity, etc.)
            payload_type: Type of payload (sqli, xss, cmdi)
            failed_attempts: Previously failed payloads to avoid
            
        Returns:
            GeneratedExploit with adapted payloads
        """
        if not self.is_available():
            return None
        
        failed_attempts = failed_attempts or []
        
        prompt = f"""Adapt this {payload_type} payload to bypass {waf_type} WAF:

Original payload: {original_payload}

Previously failed attempts (avoid these patterns):
{chr(10).join(f'- {p}' for p in failed_attempts) if failed_attempts else 'None'}

Generate 5-10 bypass variants using different techniques:
1. Encoding variations (URL, double URL, Unicode, hex)
2. Case manipulation
3. Comment insertion
4. Alternative syntax
5. Chunked/fragmented payload

Output each variant on a new line, starting with the technique name:
[TECHNIQUE] payload"""

        system_prompt = self.system_prompts[GenerationType.WAF_BYPASS]
        response = self.ollama_client.generate(prompt, system_prompt)
        
        if response:
            return self._parse_waf_bypass_response(response, original_payload, waf_type)
        
        return None
    
    def generate_attack_chain(
        self,
        vulnerabilities: List[Dict[str, Any]],
        target: Dict[str, Any],
        objective: str = "shell"
    ) -> Optional[GeneratedExploit]:
        """
        Generate a multi-step attack chain.
        
        Args:
            vulnerabilities: List of discovered vulnerabilities
            target: Target context
            objective: End goal (shell, data_exfil, persistence, privesc)
            
        Returns:
            GeneratedExploit with attack chain plan
        """
        if not self.is_available():
            return None
        
        vuln_summary = "\n".join([
            f"- {v.get('type', 'unknown')}: {v.get('description', 'No description')[:100]}"
            for v in vulnerabilities[:10]  # Limit to 10
        ])
        
        prompt = f"""Design a multi-step attack chain for authorized penetration testing.

Target: {target.get('url', target.get('host', 'unknown'))}
OS: {target.get('os', 'unknown')}
Technologies: {', '.join(target.get('technologies', ['unknown']))}

Discovered Vulnerabilities:
{vuln_summary}

Objective: {objective}

Create an attack chain that:
1. Starts with initial access using the most reliable vulnerability
2. Chains subsequent steps logically
3. Includes fallback options if a step fails
4. Ends with achieving the objective

Output format:
STEP 1: [Action]
- Vulnerability used: [type]
- Command/Payload: [specific command]
- Expected result: [what success looks like]
- Fallback: [alternative if this fails]

STEP 2: ...
(continue for all steps)

CLEANUP:
- [cleanup commands]"""

        system_prompt = self.system_prompts[GenerationType.ATTACK_CHAIN]
        response = self.ollama_client.generate(prompt, system_prompt)
        
        if response:
            return self._parse_attack_chain_response(response, objective, vulnerabilities)
        
        return None
    
    def generate_custom_payload(
        self,
        payload_type: str,
        context: Dict[str, Any],
        requirements: List[str] = None
    ) -> Optional[GeneratedExploit]:
        """
        Generate a custom payload based on requirements.
        
        Args:
            payload_type: Type (reverse_shell, sqli, xss, lfi, etc.)
            context: Target context
            requirements: Specific requirements
            
        Returns:
            GeneratedExploit with custom payload
        """
        if not self.is_available():
            return None
        
        requirements = requirements or []
        
        prompt = f"""Generate a custom {payload_type} payload for authorized security testing.

Target Context:
- URL/Host: {context.get('target', 'unknown')}
- OS: {context.get('os', 'linux')}
- WAF: {context.get('waf', 'unknown')}
- Technologies: {', '.join(context.get('technologies', []))}

Requirements:
{chr(10).join(f'- {r}' for r in requirements) if requirements else '- Standard payload'}

For reverse shell, use:
- LHOST: {context.get('lhost', '10.10.14.1')}
- LPORT: {context.get('lport', '4444')}

Generate the payload with:
1. The payload itself
2. Execution command
3. Success indicators
4. Cleanup if needed"""

        system_prompt = self.system_prompts[GenerationType.PAYLOAD_ADAPT]
        response = self.ollama_client.generate(prompt, system_prompt)
        
        if response:
            return self._parse_payload_response(response, payload_type, context)
        
        return None
    
    def generate_privesc_script(
        self,
        target_os: str = "linux",
        current_user: str = "www-data",
        known_info: Dict[str, Any] = None
    ) -> Optional[GeneratedExploit]:
        """
        Generate privilege escalation enumeration/exploit script.
        
        Args:
            target_os: Target OS (linux/windows)
            current_user: Current user context
            known_info: Known system information
            
        Returns:
            GeneratedExploit with privesc script
        """
        if not self.is_available():
            return None
        
        known_info = known_info or {}
        
        prompt = f"""Generate a privilege escalation script for authorized testing.

Target OS: {target_os}
Current User: {current_user}
Kernel Version: {known_info.get('kernel', 'unknown')}
SUID Binaries: {', '.join(known_info.get('suid', ['unknown'])[:10])}
Sudo Permissions: {known_info.get('sudo', 'unknown')}
Writable Directories: {', '.join(known_info.get('writable', ['unknown'])[:5])}

Generate a {"bash" if target_os == "linux" else "powershell"} script that:
1. Enumerates common privesc vectors
2. Checks for quick wins (GTFOBins, misconfigurations)
3. Attempts safe exploitation of found vectors
4. Reports findings clearly

Include safety checks to avoid system damage."""

        system_prompt = self.system_prompts[GenerationType.PRIVESC_SCRIPT]
        response = self.ollama_client.generate(prompt, system_prompt)
        
        if response:
            return self._parse_script_response(
                response, 
                GenerationType.PRIVESC_SCRIPT,
                "bash" if target_os == "linux" else "powershell"
            )
        
        return None
    
    def enhance_exploit_template(
        self,
        template_command: str,
        vulnerability: Dict[str, Any],
        target: Dict[str, Any],
        previous_result: Dict[str, Any] = None
    ) -> Optional[str]:
        """
        Enhance an existing exploit template command.
        
        Args:
            template_command: Original command from exploit_db
            vulnerability: Vulnerability details
            target: Target context
            previous_result: Result of previous attempt (for adaptation)
            
        Returns:
            Enhanced command string
        """
        if not self.is_available():
            return template_command  # Return original if LLM unavailable
        
        prompt = f"""Enhance this exploit command for better effectiveness:

Original Command: {template_command}

Vulnerability: {vulnerability.get('type', 'unknown')}
Target: {target.get('url', target.get('host', 'unknown'))}
WAF Detected: {target.get('waf', False)}
Technologies: {', '.join(target.get('technologies', []))}

{"Previous attempt failed with: " + previous_result.get('error', 'unknown error') if previous_result else ""}

Enhance the command to:
1. {"Bypass WAF if detected" if target.get('waf') else "Maintain stealth"}
2. Improve success rate
3. Add relevant flags/options

Output ONLY the enhanced command, nothing else."""

        response = self.ollama_client.generate(prompt, self.system_prompts[GenerationType.PAYLOAD_ADAPT])
        
        if response:
            # Extract just the command
            lines = response.strip().split('\n')
            for line in lines:
                line = line.strip()
                if line and not line.startswith('#') and not line.startswith('//'):
                    return line
        
        return template_command
    
    def _build_exploit_prompt(
        self,
        vulnerability: Dict[str, Any],
        target: Dict[str, Any],
        constraints: List[str],
        language: str
    ) -> str:
        """Build prompt for exploit generation"""
        
        vuln_type = vulnerability.get('type', 'unknown')
        cve = vulnerability.get('cve', vulnerability.get('cve_id', ''))
        details = vulnerability.get('details', vulnerability.get('description', ''))
        
        prompt = f"""Generate a {language} exploit for authorized penetration testing.

VULNERABILITY:
- Type: {vuln_type}
{"- CVE: " + cve if cve else ""}
- Details: {details[:500] if details else "Standard " + vuln_type}

TARGET:
- URL/Host: {target.get('url', target.get('host', 'unknown'))}
- Port: {target.get('port', '80')}
- OS: {target.get('os', 'unknown')}
- Technologies: {', '.join(target.get('technologies', ['unknown']))}
- WAF: {target.get('waf', 'unknown')}

{"CONSTRAINTS:" + chr(10) + chr(10).join(f"- {c}" for c in constraints) if constraints else ""}

REQUIREMENTS:
1. Include proper error handling
2. Add success/failure indicators
3. Be targeted and precise
4. Include cleanup if needed
5. Use LHOST={target.get('lhost', '10.10.14.1')} LPORT={target.get('lport', '4444')} for callbacks

Generate the complete {language} exploit code:"""

        return prompt
    
    def _parse_exploit_response(
        self,
        response: str,
        gen_type: GenerationType,
        language: str,
        vulnerability: Dict
    ) -> GeneratedExploit:
        """Parse LLM response into GeneratedExploit"""
        
        # Extract code blocks
        code = self._extract_code(response, language)
        
        # Extract steps/instructions
        steps = self._extract_steps(response)
        
        # Extract success indicators
        indicators = self._extract_indicators(response)
        
        # Calculate confidence based on response quality
        confidence = self._calculate_confidence(code, response)
        
        return GeneratedExploit(
            code=code,
            language=language,
            description=f"LLM-generated exploit for {vulnerability.get('type', 'unknown')}",
            generation_type=gen_type,
            execution_steps=steps,
            success_indicators=indicators,
            confidence=confidence,
            metadata={
                "vulnerability": vulnerability,
                "raw_response_length": len(response)
            }
        )
    
    def _parse_waf_bypass_response(
        self,
        response: str,
        original: str,
        waf_type: str
    ) -> GeneratedExploit:
        """Parse WAF bypass response"""
        
        # Extract bypass variants
        lines = response.strip().split('\n')
        variants = []
        
        for line in lines:
            line = line.strip()
            if line and not line.startswith('#'):
                # Remove technique prefix if present
                if ']' in line:
                    line = line.split(']', 1)[-1].strip()
                if line and line != original:
                    variants.append(line)
        
        code = '\n'.join(variants[:10])  # Top 10 variants
        
        return GeneratedExploit(
            code=code,
            language="payload",
            description=f"WAF bypass variants for {waf_type}",
            generation_type=GenerationType.WAF_BYPASS,
            execution_steps=[f"Try each variant in order", "Monitor for success indicators"],
            success_indicators=["200 OK", "data returned", "no block"],
            confidence=0.6,
            metadata={
                "original_payload": original,
                "waf_type": waf_type,
                "variant_count": len(variants)
            }
        )
    
    def _parse_attack_chain_response(
        self,
        response: str,
        objective: str,
        vulnerabilities: List[Dict]
    ) -> GeneratedExploit:
        """Parse attack chain response"""
        
        steps = []
        cleanup = []
        
        lines = response.split('\n')
        current_step = []
        in_cleanup = False
        
        for line in lines:
            if line.strip().upper().startswith('CLEANUP'):
                in_cleanup = True
                if current_step:
                    steps.append('\n'.join(current_step))
                    current_step = []
            elif line.strip().upper().startswith('STEP'):
                if current_step:
                    steps.append('\n'.join(current_step))
                current_step = [line]
            elif in_cleanup:
                if line.strip().startswith('-'):
                    cleanup.append(line.strip()[1:].strip())
            else:
                current_step.append(line)
        
        if current_step:
            steps.append('\n'.join(current_step))
        
        return GeneratedExploit(
            code=response,
            language="attack_chain",
            description=f"Attack chain to achieve: {objective}",
            generation_type=GenerationType.ATTACK_CHAIN,
            execution_steps=steps,
            cleanup_commands=cleanup,
            success_indicators=[objective, "access gained", "objective achieved"],
            confidence=0.5,
            metadata={
                "objective": objective,
                "vuln_count": len(vulnerabilities)
            }
        )
    
    def _parse_payload_response(
        self,
        response: str,
        payload_type: str,
        context: Dict
    ) -> GeneratedExploit:
        """Parse custom payload response"""
        
        code = self._extract_code(response, "")
        if not code:
            code = response.strip()
        
        return GeneratedExploit(
            code=code,
            language=payload_type,
            description=f"Custom {payload_type} payload",
            generation_type=GenerationType.PAYLOAD_ADAPT,
            execution_steps=self._extract_steps(response),
            success_indicators=self._extract_indicators(response),
            confidence=0.6,
            metadata={"context": context}
        )
    
    def _parse_script_response(
        self,
        response: str,
        gen_type: GenerationType,
        language: str
    ) -> GeneratedExploit:
        """Parse script generation response"""
        
        code = self._extract_code(response, language)
        
        return GeneratedExploit(
            code=code,
            language=language,
            description=f"Privilege escalation script ({language})",
            generation_type=gen_type,
            execution_steps=["Run script on target", "Review output for vectors", "Attempt exploitation"],
            success_indicators=["root", "SYSTEM", "Administrator", "uid=0"],
            confidence=0.7,
            warnings=["Ensure authorized testing", "May trigger security alerts"],
            metadata={}
        )
    
    def _extract_code(self, response: str, language: str) -> str:
        """Extract code block from response"""
        
        # Try to find code blocks
        patterns = [
            r'```' + language + r'\n(.*?)```',
            r'```\n(.*?)```',
            r'```(.*?)```',
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, response, re.DOTALL)
            if matches:
                return matches[0].strip()
        
        # If no code blocks, look for code-like content
        lines = response.split('\n')
        code_lines = []
        in_code = False
        
        for line in lines:
            # Heuristics for code detection
            if any(kw in line for kw in ['import ', 'def ', 'class ', 'function ', '#!/', 'var ', 'const ']):
                in_code = True
            if in_code or line.strip().startswith(('#', '//', '/*', 'if ', 'for ', 'while ')):
                code_lines.append(line)
        
        return '\n'.join(code_lines) if code_lines else response.strip()
    
    def _extract_steps(self, response: str) -> List[str]:
        """Extract execution steps from response"""
        steps = []
        
        # Look for numbered steps
        step_patterns = [
            r'(?:Step\s*)?(\d+)[.):]\s*(.+)',
            r'[-*]\s*(.+)',
        ]
        
        for pattern in step_patterns:
            matches = re.findall(pattern, response, re.MULTILINE)
            if matches:
                for match in matches[:10]:
                    step = match[-1] if isinstance(match, tuple) else match
                    if len(step) > 10 and len(step) < 200:
                        steps.append(step.strip())
        
        return steps[:10]  # Limit to 10 steps
    
    def _extract_indicators(self, response: str) -> List[str]:
        """Extract success indicators from response"""
        indicators = []
        
        # Common success indicator keywords
        indicator_keywords = [
            'success', 'successful', 'found', 'detected', 'vulnerable',
            'shell', 'access', 'root', 'admin', 'logged in', 'uid=',
            'database', 'dumped', 'extracted', 'connected'
        ]
        
        response_lower = response.lower()
        for keyword in indicator_keywords:
            if keyword in response_lower:
                indicators.append(keyword)
        
        return list(set(indicators))[:10]
    
    def _calculate_confidence(self, code: str, response: str) -> float:
        """Calculate confidence score for generated code"""
        score = 0.5  # Base score
        
        # Increase for code quality indicators
        if len(code) > 100:
            score += 0.1
        if 'try' in code or 'except' in code or 'catch' in code:
            score += 0.1  # Error handling
        if 'import' in code or 'require' in code:
            score += 0.05  # Imports present
        if '#' in code or '//' in code:
            score += 0.05  # Comments present
        
        # Decrease for issues
        if 'TODO' in code or 'FIXME' in code:
            score -= 0.1
        if len(code) < 50:
            score -= 0.2
        
        return min(max(score, 0.1), 0.95)  # Clamp between 0.1 and 0.95
    
    def get_stats(self) -> Dict[str, Any]:
        """Get generation statistics"""
        return {
            "total_generations": len(self.generation_history),
            "available": self.is_available(),
            "generation_types": {
                gt.value: sum(1 for g in self.generation_history if g.generation_type == gt)
                for gt in GenerationType
            },
            "avg_confidence": (
                sum(g.confidence for g in self.generation_history) / len(self.generation_history)
                if self.generation_history else 0
            )
        }


# Singleton instance
_llm_generator: Optional[LLMExploitGenerator] = None


def get_llm_exploit_generator(ollama_client=None) -> LLMExploitGenerator:
    """Get singleton LLMExploitGenerator instance"""
    global _llm_generator
    if _llm_generator is None:
        _llm_generator = LLMExploitGenerator(ollama_client)
    return _llm_generator
